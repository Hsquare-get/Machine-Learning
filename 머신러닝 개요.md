# 머신러닝 개요

- 학습 목표

  - 인공지능을 달성하기 위한 수단으로써 머신러닝을 이해
  - 머신러닝 알고리즘의 종류와 차이점을 이해
  - 일상생활 속 머신러닝이 사용되고 있는 예제

  

### 1. 인공지능과 머신러닝

> 인공지능 : 지능 작업을 수행할 수 있는 기계의 능력
>
> 머신러닝(기계학습)
>
> - 컴퓨터가 데이터로부터 지식을 직접 학습(bottom-up)
>
> - 머신러닝은 복잡성을 줄여주는 역할을 한다 -> 데이터를 많이 넣어주면 단지 몇백줄의 머신러닝 프로그램으로 여러가지 문제를 해결할 수 있다.



### 2. 머신러닝 알고리즘의 분류

#### (i) 지도학습(Supervised Learning)

> **학습 데이터마다 레이블(정답)을 가지고 있음**

- 주어진 입력-출력 쌍들을 매핑해주는 함수를 학습

- D={X(데이터), Y(정답,레이블)}로부터 F(X)=Y를 만족시키는 함수 F를 학습

- | F(X)의 형태                    |                            |
  | ------------------------------ | -------------------------- |
  | F(X)가 이산적(Discrete)일 때   | 분류 문제(Classification)  |
  | F(X)가 연속적(Continuous)일 때 | 회귀 문제(Regression)      |
  | F(X)가 X의 확률 P(X)일 때      | 확률 추정 문제(Estimation) |

- 지도학습은 정답(레이블)이 있으므로 보다 정확한 학습을 할 수 있음
- Deep-Learning이 대표적인 예
- **사용할 수 있는 데이터에 한계가 있음 **(우리 주변에 있는 대부분의 데이터는 레이블이 없음)
- 데이터를 생성하는데 비용이 많이 듦



#### (ii) 비지도학습(Unsupervised Learning)

> **학습 데이터가 레이블(정답)을 가지고 있지 않음**

- 입력만 있고 출력은 없는 상태에서 이뤄지는 학습(데이터에 내재되어있는 고유의 특징을 탐색하고자 함)

- D={X}로부터 F(X)->X를 만족시키는 함수 F를 학습
- 클러스터링이 주로 사용됨 : 비슷한 데이터끼리 묶음
- 지도학습에 비해서 학습하기 어려움



#### (iii) 강화학습(Reinforcement Learning)

> **최종 출력(정답)이 바로 주어지지 않고, 시간이 지나서 주어지는 경우**

- 예시
  - 바둑 : 승/패의 결과가 바둑기사의 한수에 주어지지 않고 시간이 지나고나서 주어짐, 바둑기사는 매 순간 바둑판의 상황을 읽고 어떤 수를 두어야할 지 고민함
- 어떤 Action이 최종 출력에 영향을 주었는지 불명확한 문제에 사용됨
- 매 순간 어떤 Action을 선택할지 판단하고 상황(State)에 대한 평가가 이루어져야한다.



### 3. 일상 생활 속 머신러닝의 예

- Netflix 추천시스템
  - 고객의 취향에 맞는 비디오를 추천(고객의 평점, 구매 내역을 활용)
  - Collaborative filtering(협업 필터링) : 많은 사용자들로부터 얻은 기호정보에 따라 사용자들의 관심사들을 자동적으로 예측하게 해주는 방법



### 4. 머신러닝의 구성 요소

#### (i) 훈련/검증/테스트 데이터

- 8:2 or 7:3 or 6:4로 훈련:검증 데이터로 분리할 수 있다.

- 훈련 데이터 : 모델 학습을 위해 사용되는 데이터

- 검증 데이터 : 모델을 검증하기 위한 데이터, 검증 데이터에 대한 성능에 따라 모델을 바꿔보고 통상적으로 성능이 제일 높은 모델을 선택

- 테스트 데이터 : 현재 우리가 가지고 있지 않지만 실제 맞닥뜨릴 데이터, 학습된 모델의 최종 성능 검사를 위해 따로 구별해 놓은 데이터

- **Cross-Validation(교차검증)**

  - 가장 일반적으로 사용되는 K-fold 교차 검증

  ![cross validation](https://user-images.githubusercontent.com/64063767/105852212-88cc1800-6027-11eb-9749-eb6c361dcef4.png)

  - **교차 검증의 장점**
    - 모든 데이터 셋을 평가에 활용할 수 있다.
      - 평가에 사용되는 데이터 편중을 막을 수 있다.
      - 특정 평가 데이터셋에 Overfitting(과대적합) 되는 것을 방지할 수 있다.
      - 평가 결과에 따라 좀 더 일반화된 모델을 만들 수 있다.
    - 모든 데이터 셋을 훈련에 활용할 수 있다.
      - 정확도를 향상시킬 수 있다.
      - 데이터 부족으로 인한 Underfitting(과소적합)을 방지할 수 있다.
  - **교차 검증의 단점**
    - Iteration 횟수가 많기 때문에 모델 훈련/평가 시간이 오래 걸린다.



#### (ii) 모델의 표현 방법

- 의사 결정 트리
  - 기호주의자(Symbolists)
  - 귀납적 추론, 철학과 심리학, 논리학에서 아이디어를 얻음

- 신경망 기반
  - 연결주의자(Connectionists)
  - 두뇌를 분석하고 모방하여 신경과학과 물리학에서 아이디어를 얻음
  - 신경 세포들 마다 연결들이 존재하는 것처럼 연결 노드의 가중치를 조절하면서 학습하게된다. 역전파 알고리즘 과정으로 학습이 되면 알고리즘의 출력을 목표값과 비교한 뒤 노드들의 가중치를 계속 조절해가면서 알고리즘 출력이 목표값에 가깝도록 학습을 해나간다.

- KNN, SVM(Support Vector Machine)
  - 유추주의자(Analogizers)
  - 기하학적 거리를 사용하여 지식을 표현. 데이터들을 기하학적 스페이스에서 봤을 때 데이터들 간 거리를 측정하여 유사성을 기반으로 다른 지식(데이터)를 추정한다.
  - 유사성 판단을 근거로 학습하고 추정하며 심리학과 수학적 최적화의 영향을 받음

- 베이지안 모델
  - 베이즈주의자(Bayesians)
  - 학습은 확률 추론의 한 형태로서 통계학에 뿌리를 둠

- 유전 알고리즘

  - 진화주의자(Evolutionaries)

  - 컴퓨터에서 진화를 모의시험하며 유전학과 진화생물학에 의존

- 모델 앙상블
  - 여러 알고리즘들의 결과를 조합하여 하나로 취합하는 방식



#### (iii) 모델의 평가 방법

- 에러의 제곱(Squared Error)
  - 정답과 모델 예측값의 차이(에러)의 제곱 값이 최소가 되도록 모델을 학습시키며 주로 회귀모델에 사용
  - sum{y-f(x)}^2 [y:정답값 / f(x):모델의 예측값]
- 정확도(Accuracy)
  - 맞힌 테스트 데이터 수 / 전체 테스트 데이터 수

- 우도(Likelihood)
  - 확률추정 문제에 주로 사용
  - 모델이 예측하고자 하는 레이블의 log확률로 모델을 평가(이 값이 높아지는 방향으로 모델을 학습시킴)

- 정밀도와 재현율(Precision & Recall)
  - 정보 검색에서 주로 사용
    - 정밀도 : 구글에 검색해서 100개의 결과를 보여줬다면 100개의 검색결과중 원하는 검색결과는 80개라면 80/100=0.8의 정밀도를 가진다.
    - 재현율 : 인터넷에 존재하는 내가 원하는 결과의 총 개수 중 구글이 검색에 성공한 결과를 나타낸 수치. 내가 원하는 정보가 인터넷에 총 1000개 존재할 때 구글이 80개까지 보여줬다면 80/1000=0.08의 재현율을 가진다.

- 엔트로피(Entropy)
  - 주로 크로스 엔트로피가 사용되는데, 크로스 엔트로피는 정답레이블의 확률과 정답레이블에 대해 예측한 확률사이의 거리를 측정해준다.
- 사후 확률(Posterior Probability)