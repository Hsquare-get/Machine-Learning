# 스케일링(Scaling)

http://hleecaster.com/ml-normalization-concept/

## 1. 데이터 스케일링 이유

> 머신러닝 알고리즘은 데이터가 가진 feature(특성)들을 비교하여 데이터의 패턴을 찾는다.
>
> 여기서 주의할 점은 **데이터가 가진 feature의 스케일이 심하게 차이가 나는 경우 문제**가 된다는 것이다. 특정 feature가 다른 feature들을 완전히 지배하게 되고 다른 feature 정보들을 버리는 꼴이 되버린다. (feature간 스케일 차이가 심하지 않다면 정규화 필요성 감소) 
>
> 모든 데이터 포인트가 동일한 정도의 스케일(중요도)로 반영되도록 해주는 것이 정규화의 목표.

<br/>

## 2. 스케일링 방법

### (1) Min-Max Normalization(최소-최대 정규화)

> 최소-최대 정규화 방법은 데이터를 정규화하는 가장 일반적인 방법이다. 모든 feature에 대해 각각 0~1 범위 안의 값으로 변환하는 것이다.
>
> 하지만, 최소-최대 정규화에는 치명적인 단점이 있다. **이상치(Outlier)에 너무 많은 영향을 받는다**는 것이다. 이러한 단점을 보완하기 위해 Z-Score 표준화 방법을 이용한다.



### (2.) Z-Score Standardization(Z-점수 표준화)

> **(X - 평균) / 표준편차**
>
> 평균이 0이고 표준편차가 1인 정규분포를 따르도록 데이터를 바꿔준다.
>
> 따라서 0을 중심으로 양쪽에 데이터를 분포시키게되고, 각 데이터들이 평균을 기준으로 얼마나 떨어져있는지를 나타내는 값으로 변환된다.
>
> 이상치(Outlier)를 잘 처리하지만, 정확히 동일한 척도로 정규화된 데이터를 생성하지는 않는다.